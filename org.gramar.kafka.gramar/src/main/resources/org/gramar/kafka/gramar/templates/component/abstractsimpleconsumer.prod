package <c:get select="$component/@kafkaBasePkg" />;

import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.StringTokenizer;

import kafka.api.PartitionFetchInfo;
import kafka.api.PartitionOffsetRequestInfo;
import kafka.cluster.BrokerEndPoint;
import kafka.common.ErrorMapping;
import kafka.common.OffsetAndMetadata;
import kafka.common.OffsetMetadata;
import kafka.common.OffsetMetadataAndError;
import kafka.common.OffsetOutOfRangeException;
import kafka.common.TopicAndPartition;
import kafka.javaapi.FetchRequest;
import kafka.javaapi.FetchResponse;
import kafka.javaapi.OffsetCommitRequest;
import kafka.javaapi.OffsetFetchRequest;
import kafka.javaapi.OffsetFetchResponse;
import kafka.javaapi.OffsetRequest;
import kafka.javaapi.OffsetResponse;
import kafka.javaapi.PartitionMetadata;
import kafka.javaapi.TopicMetadata;
import kafka.javaapi.TopicMetadataRequest;
import kafka.javaapi.TopicMetadataResponse;
import kafka.javaapi.consumer.SimpleConsumer;
import kafka.javaapi.message.ByteBufferMessageSet;
import kafka.message.MessageAndOffset;

import <c:get select="$component/@exceptionPkg" />.*;

public class AbstractSimpleConsumer {
	
	// List of brokers managing the topic's partitions
	private List<String> replicaBrokers = new ArrayList<String>();
	
	// List of (at least some of the) brokers in the Kafka cluster 
	private List<String> seedBrokers = new ArrayList<String>();
	
	// List of the ports corresponding to the hosts in seedBrokers
	private List<Integer> ports = new ArrayList<Integer>();
	
	// The port the brokers listen on
//	private int port;

	// The topic from which to read
	protected String topic;
	
	// The partition of the topic from which to read
	protected int partition;
	
	// The name of the client group
	private String groupName;
	
	// How long to wait
	private int timeout = 10000;
	
	// Number of bytes to fetch
	private int fetchSize = 100000;
	
	// How many times to retry a fetch before failing
	private int fetchRetries = 5;
	
	private String clientName;
	
	// An arbitrary string of data to be stored with partition offset
	private String consumerMetadata = "";
	
	private SimpleConsumer simpleConsumer = null;
	
	// The host, port, etc. of the broker operating the primary replica for 
	// the current partition
	private BrokerEndPoint leadBroker = null;
	
	private MessageAndOffset nextMessageAndOffset = null;
	
	// Offset of the first unread message (the next message to be read)
	// This value advances as messages are read in preparation for fast return to a client
	private Long firstUnread = null;
	
	// Offset of the last returned message
	// This value will only advance when a message is returned to a client and is used on close()
	private Long nextOffsetToReturn = null;
	
	// Iterator over messages retrieved by most recent fetch
	private Iterator<MessageAndOffset> messageSetIterator;
	
	// How long (milliseconds) to sleep if there are no messages in the partition
	private long emptyWait = 1000;
	
	// Force the consumer to start reading at the beginning of the partition
	private boolean startAtBeginning = false;
	
	// Force the consumer to start reading at the end of the partition
	private boolean startAtEnd = false;
	
	// Force a commit at least every x number of milliseconds.  The commit happens on the first retrieve after that interval has elapsed.
	protected long autoCommitInterval = 1000; 
	
	// The system time in milliseconds after which the next auto commit will happen.  Calculated on each commit for the next commit.
	private long nextCommitTime = 0L;
	
	public AbstractSimpleConsumer(String csBrokerList, String topic, int partition, String groupName) {
		parse(csBrokerList);
		this.topic = topic;
		this.partition = partition;
		this.groupName = groupName;
        clientName = "Client_" + topic + "_" + partition;
//        determineFirstUnread();
	}

	private void parse(String csBrokerList) {
		StringTokenizer st = new StringTokenizer(csBrokerList, ", \t\n");
		while (st.hasMoreTokens()) {
			String hostPort = st.nextToken();
			StringTokenizer st1 = new StringTokenizer(hostPort, ":");
			seedBrokers.add(st1.nextToken());
			int port = 9092;
			try { port = Integer.parseInt(st1.nextToken()); } catch (Throwable t) {  }
			ports.add(port);
		}
	}

	public boolean hasNext() {
		if (nextMessageAndOffset == null) {
			nextMessageAndOffset = nextMessage();
		}
		return nextMessageAndOffset != null;
	}
	
	public void autoCommitOff() {
		autoCommitInterval = 0L;
	}
	
	protected MessageAndOffset requestSpecificOffset(long offset) {
		nextMessageAndOffset = null;
		messageSetIterator = null;
		firstUnread = offset;
		return nextMessage();
	}
	
	protected MessageAndOffset nextMessage() {
		for (int attempt = 0; attempt < fetchRetries; attempt++) {
			try {
				MessageAndOffset mao = nextMessage0();
				long now = System.currentTimeMillis();
				if (nextCommitTime == 0L) {
		        	nextCommitTime = now + autoCommitInterval;
				}
		    	if ((autoCommitInterval > 0L) && (nextOffsetToReturn!=null) && (now < nextCommitTime)) {
		        	commitOffset(nextOffsetToReturn);
		        	nextCommitTime = now + autoCommitInterval;
		    	}

				return mao;
			} catch (PartitionConsumerException e) {
			}
		}
		return null;
	}
	
	private MessageAndOffset nextMessage0() throws PartitionConsumerException {
		MessageAndOffset result  = null;
		
		if (nextMessageAndOffset != null) {
			result = nextMessageAndOffset;
			nextMessageAndOffset = null;
			nextOffsetToReturn = result.nextOffset();
			return result;
		}

		if ((messageSetIterator == null) || (!messageSetIterator.hasNext())) {
			messageSetIterator = fetch();
			if (!messageSetIterator.hasNext()) {
				messageSetIterator = null;
				try { Thread.sleep(emptyWait); } catch (Throwable t) {  }
				return null;
			}
		}
		
		MessageAndOffset messageAndOffset = messageSetIterator.next();
        long currentOffset = messageAndOffset.offset();
        if (currentOffset < firstUnread) {
            throw new OldMessageException("Found an old offset: " + currentOffset + " Expecting: " + firstUnread);
        }

        firstUnread = messageAndOffset.nextOffset();
		nextOffsetToReturn = messageAndOffset.nextOffset();
        return messageAndOffset;
		
	}

    @SuppressWarnings({ "unchecked", "rawtypes" })
	private Iterator<MessageAndOffset> fetch() throws PartitionConsumerException {

    	if (firstUnread == null) {
    		determineFirstUnread();
    	}
    	
    	Map<TopicAndPartition,PartitionFetchInfo> requestInfo = new HashMap<TopicAndPartition,PartitionFetchInfo>();
    	TopicAndPartition tap = new TopicAndPartition(topic,partition);
    	PartitionFetchInfo pfi = new PartitionFetchInfo(firstUnread, fetchSize);
    	requestInfo.put(tap,pfi);
        FetchRequest fetchRequest = new FetchRequest(0, clientName, timeout, 1, requestInfo);
        FetchResponse fetchResponse;
		try {
			fetchResponse = getSimpleConsumer().fetch(fetchRequest);
		} catch (Exception e) {
	        return new ByteBufferMessageSet(new ArrayList()).iterator();
		}
 
        if (fetchResponse.hasError()) {

            short code = fetchResponse.errorCode(topic, partition);
            if (code == ErrorMapping.OffsetOutOfRangeCode())  {
                // We asked for an invalid offset. For simple case ask for the last element to reset
                firstUnread = retrieveOffset();
                cleanConsumer();
                throw new OffsetOutOfRangeException();
            }

            cleanConsumer();
            throw new PartitionConsumerException("Error fetching data from the Broker:" + getLeadBroker() + " Reason: " + code);

        }
                
        ByteBufferMessageSet bbms = fetchResponse.messageSet(topic, partition);
        return bbms.iterator();
        
    }
    
    private SimpleConsumer getSimpleConsumer() throws PartitionConsumerException {
    	if (simpleConsumer==null) { 
    		simpleConsumer = new SimpleConsumer(getLeadBroker().host(), getLeadBroker().port(), timeout, 64 * 1024, clientName);
    	}
    	return simpleConsumer;
    }
    
    private void cleanConsumer() {
    	if (simpleConsumer!=null) { 
    		simpleConsumer.close();
    	}
    	simpleConsumer = null;
        // Force a search for a new lead broker
        leadBroker = null;
    }
    
    public void close() throws PartitionConsumerException {
    	cleanConsumer();
    	if (nextOffsetToReturn!=null) {
        	commitOffset(nextOffsetToReturn);
    	}
    }
    
    /**
     * Return cached information about the lead broker for this partition. 
     * @return BrokerEndPoint describing the lead broker
     * @throws PartitionConsumerException
     */
    private BrokerEndPoint getLeadBroker() throws PartitionConsumerException {
    	if (leadBroker==null) {
    		leadBroker = findNewLeadBroker();
    	}
    	return leadBroker;
    }
    
    
    /**
     * Return the next unread offset for the partition.  This method takes into account
     * the raw (actual committed offset) with respect to the earliest available offset, 
     * latest available offset and startAt* options.
       
     * @return BrokerEndPoint describing the lead broker
     * @throws PartitionConsumerException
     */
    public Long getFirstUnread() {
    	determineFirstUnread();
    	return firstUnread;
    }

	private void determineFirstUnread() {
		
		try {

			long earliest = requestEarliestAvailableOffset();
			long latest = requestLatestAvailableOffset();
			if (startAtBeginning) { 
				// Flag was set forcing us back to the beginning of the partition
				firstUnread = earliest;
			} else if (startAtEnd) {
				// Flag was set forcing us forward to the end (most recent message) of the partition
				firstUnread = latest + 1;
			} else {
				// Look to see if we previously committed an offset for this partition
				firstUnread = retrieveOffset();
				
				if (firstUnread < earliest) {
					firstUnread = earliest;
				}
				
				if (firstUnread > latest+1) {
					firstUnread = latest+1;
				}
			}
			
		} catch (PartitionConsumerException e) {
			
			// gotta start somewhere
			firstUnread = 0L; 
		}

		
	}


    /**
     * Commits the current offset as being the offset of the next message to be read. 
     */
	public void commitOffset() throws PartitionConsumerException {
		if (nextOffsetToReturn==null) { return; }
    	commitOffset(nextOffsetToReturn);
	}

    /**
     * Commits the given offset as being the offset of the next message to be read. 
     */
	private void commitOffset(long offset) throws PartitionConsumerException {
    	
        Map<TopicAndPartition, OffsetAndMetadata> requestInfo = new HashMap<TopicAndPartition, OffsetAndMetadata>();
        TopicAndPartition topicAndPartition = new TopicAndPartition(topic, partition);
        OffsetMetadata omd = new OffsetMetadata(offset, consumerMetadata);
        OffsetAndMetadata oamd = new OffsetAndMetadata(omd, System.currentTimeMillis(), System.currentTimeMillis());
        requestInfo.put(topicAndPartition, oamd);
    	OffsetCommitRequest request = new OffsetCommitRequest(groupName, requestInfo, 0, clientName, (short) 0);
    	getSimpleConsumer().commitOffsets(request);

	}

    /**
     * Retrieves the previously committed offset. If no offset has been committed, yet, a -1 is returned.
     */
	public long retrieveOffset() throws PartitionConsumerException {
    	
        List<TopicAndPartition> requestInfo = new ArrayList<TopicAndPartition>();
        TopicAndPartition topicAndPartition = new TopicAndPartition(topic, partition);
        requestInfo.add(topicAndPartition);
        
    	OffsetFetchRequest request = new OffsetFetchRequest(groupName, requestInfo, (short) 0, 0, clientName);
    	
    	OffsetFetchResponse response = getSimpleConsumer().fetchOffsets(request);
    	Map<TopicAndPartition, OffsetMetadataAndError> offsets = response.offsets();
    	OffsetMetadataAndError omae = offsets.get(new TopicAndPartition(topic, partition));
    	
    	return omae.offset();

	}
    
	public long requestEarliestAvailableOffset() throws PartitionConsumerException {
		return requestOffset(-2);
	}
    
	public long requestLatestAvailableOffset() throws PartitionConsumerException {
		return requestOffset(-1);
	}
	
	/*
	 * Request the offset for the current partition:
	 *   time = -1 returns the latest offset
	 *   time = -2 returns the earliest available offset
	 */
    private long requestOffset(long time) throws PartitionConsumerException {
        
    	TopicAndPartition topicAndPartition = new TopicAndPartition(topic, partition);
        Map<TopicAndPartition, PartitionOffsetRequestInfo> requestInfo = new HashMap<TopicAndPartition, PartitionOffsetRequestInfo>();
        requestInfo.put(topicAndPartition, new PartitionOffsetRequestInfo(time, 1));
        
        OffsetRequest request = new OffsetRequest(requestInfo, (short)0, clientName);
        OffsetResponse response = getSimpleConsumer().getOffsetsBefore(request);
 
        if (response.hasError()) {
        	throw new PartitionConsumerException("Error fetching data Offset Data the Broker. Reason: " + response.errorCode(topic, partition));
        }
        long[] offsets = response.offsets(topic, partition);
        return offsets[0];
    }
    
    public TopicMetadata getMetaData() throws PartitionConsumerException {

        for (String seed : seedBrokers) {
            SimpleConsumer consumer = null;
            try {
                consumer = new SimpleConsumer(seed, portForSeed(seed), timeout, 64 * 1024, "leaderLookup");
                List<String> topics = Collections.singletonList(topic);
                TopicMetadataRequest req = new TopicMetadataRequest(topics);
                TopicMetadataResponse resp = consumer.send(req);
 
                List<TopicMetadata> metaData = resp.topicsMetadata();
                return metaData.get(0);
            } catch (Exception e) {
            	throw new PartitionConsumerException("Error communicating with Broker ('" + seed + "') to find meta data for topic ('"+topic+"')",e);
            } finally {
                if (consumer != null) consumer.close();
            }
        }

       	throw new PartitionConsumerException("Can't find metadata for topic ('"+topic+"') and partition ("+partition+")");

    }
 
    /**
     * Find the lead broker for the current partition.
     * @return The BrokerEndPoint representing the broker running the primary replica for this partition
     * @throws PartitionConsumerException
     */
    private BrokerEndPoint findNewLeadBroker() throws PartitionConsumerException {

        for (String seed : seedBrokers) {
            SimpleConsumer consumer = null;
            try {
                consumer = new SimpleConsumer(seed, portForSeed(seed), timeout, 64 * 1024, "leaderLookup");
                List<String> topics = Collections.singletonList(topic);
                TopicMetadataRequest req = new TopicMetadataRequest(topics);
                TopicMetadataResponse resp = consumer.send(req);
 
                List<TopicMetadata> metaData = resp.topicsMetadata();
                for (TopicMetadata item : metaData) {
                    for (PartitionMetadata part : item.partitionsMetadata()) {
                        if (part.partitionId() == partition) {

                            replicaBrokers.clear();
                            for (BrokerEndPoint replica : part.replicas()) {
                                replicaBrokers.add(replica.host());
                            }

                            if (part.leader() == null) {
                            	throw new PartitionConsumerException("Can't find leader for topic ('"+topic+"') and partition ("+partition+")");
                            }
                            
                            return part.leader();
                        }
                    }
                }
            } catch (Exception e) {
            	throw new PartitionConsumerException("Error communicating with Broker ('" + seed + "') to find Leader for topic ('"+topic+"') and partition ("+partition+")",e);
            } finally {
                if (consumer != null) consumer.close();
            }
        }

       	throw new PartitionConsumerException("Can't find metadata for topic ('"+topic+"') and partition ("+partition+")");

    }

	private int portForSeed(String seed) {
		for (int i = 0; i < seedBrokers.size(); i++) {
			if (seed.equals(seedBrokers.get(i))) {
				return ports.get(i);
			}
		}
		return 9092;
	}

	public void setTimeout(int timeout) {
		this.timeout = timeout;
	}

	public void setTimeout(String timeout) {
		if (timeout==null) { return; }
		this.timeout = Integer.parseInt(timeout);
	}

	public void setFetchSize(int fetchSize) {
		this.fetchSize = fetchSize;
	}

	public void setFetchSize(String fetchSize) {
		if (fetchSize==null) { return; }
		this.fetchSize = Integer.parseInt(fetchSize);
	}

	public void setFetchRetries(int fetchRetries) {
		this.fetchRetries = fetchRetries;
	}

	public void setFetchRetries(String fetchRetries) {
		if (fetchRetries==null) { return; }
		this.fetchRetries = Integer.parseInt(fetchRetries);
	}

	public void setEmptyWait(long emptyWait) {
		this.emptyWait = emptyWait;
	}

	public void setEmptyWait(String emptyWait) {
		if (emptyWait==null) { return; }
		this.emptyWait = Long.parseLong(emptyWait);
	}

	public void setStartAtBeginning(boolean startAtBeginning) {
		this.startAtBeginning = startAtBeginning;
	}

	public void setStartAtBeginning(String startAtBeginning) {
		if (startAtBeginning==null) { return; }
		this.startAtBeginning = Boolean.parseBoolean(startAtBeginning);
	}

	public void setStartAtEnd(boolean startAtEnd) {
		this.startAtEnd = startAtEnd;
	}

	public void setStartAtEnd(String startAtEnd) {
		if (startAtEnd==null) { return; }
		this.startAtEnd = Boolean.parseBoolean(startAtEnd);
	}
  
}
